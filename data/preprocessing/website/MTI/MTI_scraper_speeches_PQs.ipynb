{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ed555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8541d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File with URLs\n",
    "urls_file = \"websites_speeches_pqs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb0f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "dates = []\n",
    "contents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca96ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_title(soup):\n",
    "    #Select relevant CSS pattern\n",
    "    article_title = soup.select('div[class=\"article-title\"] > h1[class=\"hide-mobile\"]')\n",
    "    #Return title text\n",
    "    return article_title[0].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38223295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_date(soup):\n",
    "    #Select relevant CSS pattern\n",
    "    article_date = soup.select('div[class=\"info-date\"]')\n",
    "    #Obtain date\n",
    "    date = article_date[0].get_text().strip()\n",
    "    #Convert date to datetime format\n",
    "    return datetime.strptime(date, '%d %b %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aef5e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_content(soup):\n",
    "    #Initiate empty string\n",
    "    string = ''\n",
    "    \n",
    "    #Select relevant CSS pattern\n",
    "    article_content = soup.select('div[class*=\"article-content\"]')\n",
    "    \n",
    "    #Extract all article text and combine into the same string\n",
    "    for con in article_content:\n",
    "        string += con.get_text()\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7165569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read URL csv\n",
    "urls = pd.read_csv(urls_file)['URLs']\n",
    "\n",
    "#Extract content from each url\n",
    "for url in urls:\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content, features=\"html.parser\")\n",
    "    \n",
    "    titles.append(get_article_title(soup))\n",
    "    dates.append(get_article_date(soup))\n",
    "    contents.append(get_article_content(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47084dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to CSV\n",
    "scraped_df = pd.DataFrame(zip(titles, dates, contents), columns = ['Title', 'Date', 'Content'])\n",
    "scraped_df.to_csv(\"MTI_speeches_PQs_scraped.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
